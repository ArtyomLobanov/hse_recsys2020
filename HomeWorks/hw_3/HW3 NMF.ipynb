{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATING_THRESHOLD = 4\n",
    "PREFIX_LEN = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('big_data/rating.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'genres'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('big_data/movie.csv')\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_by_id = {movie_id: name for movie_id, name in zip(movies_df['movieId'], movies_df['title'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = max(df['userId']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies = max(df['movieId']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_by_user = defaultdict(list)\n",
    "requests_by_user = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userId, movieId, rating in zip(df['userId'], df['movieId'], df['rating']):\n",
    "    if rating > RATING_THRESHOLD:\n",
    "        items_by_user[userId].append(movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userId, movies in items_by_user.items():\n",
    "    for i in range(PREFIX_LEN, len(movies)):\n",
    "        requests_by_user[userId].append((movies[i - PREFIX_LEN:i], movies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_to_dataset(requests, n_movies, n_negative):\n",
    "    users, movies, targets = [], [], []\n",
    "    for user, session in requests.items():\n",
    "        for prev, movie in session:\n",
    "            users.append(user)\n",
    "            movies.append(movie)\n",
    "            targets.append(1)\n",
    "            \n",
    "            for i in range(n_negative):\n",
    "                users.append(user)\n",
    "                movies.append(random.randint(0, n_movies - 1))\n",
    "                targets.append(0)\n",
    "                \n",
    "    return TensorDataset(torch.LongTensor(users), torch.LongTensor(movies), torch.FloatTensor(targets).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_requests(requests):\n",
    "    train_requests, val_requests, test_requests = {}, {}, {}\n",
    "    for user, datas in requests.items():\n",
    "        user_cnt = len(datas)\n",
    "        train_size = (8 * user_cnt - 1) // 10 + 1\n",
    "        val_size = (user_cnt - train_size) // 2\n",
    "        \n",
    "        train_requests[user] = datas[:train_size]\n",
    "        val_requests[user] = datas[train_size:(train_size + val_size)]\n",
    "        test_requests[user] = datas[(train_size + val_size):]\n",
    "    return train_requests, val_requests, test_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_requests, val_requests, test_requests = split_requests(requests_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30850479\n"
     ]
    }
   ],
   "source": [
    "train_dataset = requests_to_dataset(train_requests, n_movies, 10)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3326873\n"
     ]
    }
   ],
   "source": [
    "val_dataset = requests_to_dataset(val_requests, n_movies, 10)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3836074\n"
     ]
    }
   ],
   "source": [
    "test_dataset = requests_to_dataset(test_requests, n_movies, 10)\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embeddings_dim=64, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embeddings_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embeddings_dim)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(2 * embeddings_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size))\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(embeddings_dim + hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_embedding(user)\n",
    "        i = self.item_embedding(item)\n",
    "        \n",
    "        cross = u * i\n",
    "        hidden = self.encoder(torch.cat([u, i], dim=-1))\n",
    "        return self.predictor(torch.cat([cross, hidden], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, opt, train, test, n_epochs, batch_size, device='cuda'):\n",
    "    train_loader = DataLoader(train, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            users, movies, targets = batch\n",
    "            predictions = model(users.to(device), movies.to(device))\n",
    "            loss_value = loss(predictions, targets.to(device))\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_predictions = np.zeros(len(test))\n",
    "            test_targets = np.zeros(len(test))\n",
    "            \n",
    "            ptr = 0\n",
    "            for batch in test_loader:\n",
    "                users, movies, targets = batch\n",
    "                predictions = model(users.to(device), movies.to(device))\n",
    "                predictions = predictions.detach().cpu().numpy().flatten()\n",
    "                test_predictions[ptr:ptr + len(predictions)] = predictions\n",
    "                test_targets[ptr:ptr + len(targets)] = targets.numpy().flatten()\n",
    "            \n",
    "            print(f'After {i + 1} epochs AUC = {roc_auc_score(test_targets, test_predictions)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_users, n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 epochs AUC = 0.6591797963655154\n",
      "After 2 epochs AUC = 0.6754230200423118\n",
      "After 3 epochs AUC = 0.6785140648417621\n",
      "After 4 epochs AUC = 0.7113097227880175\n",
      "After 5 epochs AUC = 0.7178320666615207\n"
     ]
    }
   ],
   "source": [
    "train(model, loss, optimizer, train_dataset, val_dataset, 5, 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.item_embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return x.dot(y) / (norm(x) * norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(embeddings, vector, n_samples=10):\n",
    "    results = []\n",
    "    for movie_id, movie_name in movie_by_id.items():\n",
    "        sim = cosine_similarity(embeddings[movie_id], vector)\n",
    "        results.append((sim, movie_id, movie_name))\n",
    "    results.sort(reverse=True)\n",
    "    return results[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similars_for(movie_id):\n",
    "    for sim, movie_id, movie_name in get_similar(embeddings, embeddings[movie_id]):\n",
    "        print(f'sim={sim:.2f}| id:{movie_id}\\t{movie_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim=1.00| id:76093\tHow to Train Your Dragon (2010)\n",
      "sim=0.48| id:54771\tInvasion, The (2007)\n",
      "sim=0.44| id:827\tConvent, The (O Convento) (1995)\n",
      "sim=0.44| id:30810\tLife Aquatic with Steve Zissou, The (2004)\n",
      "sim=0.43| id:7920\tDesperate Living (1977)\n",
      "sim=0.43| id:1649\tFast, Cheap & Out of Control (1997)\n",
      "sim=0.42| id:7151\tGirl with a Pearl Earring (2003)\n",
      "sim=0.42| id:2113\tGraveyard Shift (Stephen King's Graveyard Shift) (1990)\n",
      "sim=0.42| id:128616\tAs We Were Dreaming (2015)\n",
      "sim=0.42| id:47904\tNotti bianche, Le (White Nights) (1957)\n"
     ]
    }
   ],
   "source": [
    "show_similars_for(76093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim=1.00| id:480\tJurassic Park (1993)\n",
      "sim=0.47| id:69406\tProposal, The (2009)\n",
      "sim=0.46| id:61075\tElegy (2008)\n",
      "sim=0.44| id:8492\tChristmas Carol, A (Scrooge) (1951)\n",
      "sim=0.44| id:46976\tStranger than Fiction (2006)\n",
      "sim=0.42| id:62235\tRed (2008)\n",
      "sim=0.42| id:37976\tFlowers of St. Francis (Francesco, giullare di Dio) (1950)\n",
      "sim=0.41| id:4933\tEarthling, The (1980)\n",
      "sim=0.41| id:899\tSingin' in the Rain (1952)\n",
      "sim=0.40| id:98491\tPaperman (2012)\n"
     ]
    }
   ],
   "source": [
    "show_similars_for(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_movies(user_id):\n",
    "    requests = train_requests[user_id]\n",
    "    return requests[0][0] + [request[1] for request in requests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_user_recommendations(user_id):\n",
    "    train_movies = get_train_movies(user_id)\n",
    "    print('User movies:')\n",
    "    for movie_id in train_movies:\n",
    "        print(f'\\t{movie_by_id[movie_id]}')\n",
    "    recommendations = []\n",
    "    user = torch.LongTensor([user_id]).to('cuda')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_movies):\n",
    "            score = model(user, torch.LongTensor([i]).to('cuda')).item()\n",
    "            recommendations.append((score, i))\n",
    "    recommendations.sort(reverse=True)\n",
    "    print('\\nRecomendations:')\n",
    "    for score, i in recommendations[:10]:\n",
    "        print(f'\\t{movie_by_id[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User movies:\n",
      "\tAmerican President, The (1995)\n",
      "\tClueless (1995)\n",
      "\tWaiting to Exhale (1995)\n",
      "\tSense and Sensibility (1995)\n",
      "\tPersuasion (1995)\n",
      "\tApollo 13 (1995)\n",
      "\tBefore Sunrise (1995)\n",
      "\tBullets Over Broadway (1994)\n",
      "\tClerks (1994)\n",
      "\tHoop Dreams (1994)\n",
      "\tMiami Rhapsody (1995)\n",
      "\tRemains of the Day, The (1993)\n",
      "\n",
      "Recomendations:\n",
      "\tShawshank Redemption, The (1994)\n",
      "\tPulp Fiction (1994)\n",
      "\tStar Wars: Episode IV - A New Hope (1977)\n",
      "\tSilence of the Lambs, The (1991)\n",
      "\tSchindler's List (1993)\n",
      "\tBlade Runner (1982)\n",
      "\tForrest Gump (1994)\n",
      "\tStar Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\tFight Club (1999)\n",
      "\tLord of the Rings: The Return of the King, The (2003)\n"
     ]
    }
   ],
   "source": [
    "show_user_recommendations(46380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User movies:\n",
      "\tMr. Holland's Opus (1995)\n",
      "\tFriday the 13th (1980)\n",
      "\tStar Wars: Episode VI - Return of the Jedi (1983)\n",
      "\tStar Trek: First Contact (1996)\n",
      "\tTerminator 2: Judgment Day (1991)\n",
      "\tStand by Me (1986)\n",
      "\tRules of Engagement (2000)\n",
      "\tFrom Russia with Love (1963)\n",
      "\tTime Machine, The (1960)\n",
      "\tFrom Dusk Till Dawn (1996)\n",
      "\tFemme Nikita, La (Nikita) (1990)\n",
      "\tJurassic Park (1993)\n",
      "\tFantastic Voyage (1966)\n",
      "\tLegends of the Fall (1994)\n",
      "\tAbbott and Costello Meet Frankenstein (1948)\n",
      "\tGrumpy Old Men (1993)\n",
      "\tAmityville Horror, The (1979)\n",
      "\tCreature from the Black Lagoon, The (1954)\n",
      "\tLost World: Jurassic Park, The (1997)\n",
      "\t2001: A Space Odyssey (1968)\n",
      "\tStar Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\tBack to the Future (1985)\n",
      "\tAlien (1979)\n",
      "\n",
      "Recomendations:\n",
      "\tShawshank Redemption, The (1994)\n",
      "\tPulp Fiction (1994)\n",
      "\tStar Wars: Episode IV - A New Hope (1977)\n",
      "\tMatrix, The (1999)\n",
      "\tForrest Gump (1994)\n",
      "\tSilence of the Lambs, The (1991)\n",
      "\tLord of the Rings: The Return of the King, The (2003)\n",
      "\tUsual Suspects, The (1995)\n",
      "\tBraveheart (1995)\n",
      "\tTerminator 2: Judgment Day (1991)\n"
     ]
    }
   ],
   "source": [
    "show_user_recommendations(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets, users):\n",
    "    user_pred = {}\n",
    "    user_target = {}\n",
    "    for p, t, user in zip(pred, targets, users):\n",
    "        if user not in user_pred:\n",
    "            user_pred[user] = []\n",
    "            user_target[user] = []\n",
    "        user_pred[user].append(p)\n",
    "        user_target[user].append(t)\n",
    "    auc_per_user = []\n",
    "    for user in user_pred:\n",
    "        try:\n",
    "            auc_per_user.append(roc_auc_score(user_target[user], user_pred[user]))\n",
    "        except ValueError:\n",
    "            auc_per_user.append(0.5)\n",
    "    metric_values = {\n",
    "        'per_user_auc': np.mean(auc_per_user), \n",
    "        'auc': roc_auc_score(targets, pred)\n",
    "    }\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, 50000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_users = np.zeros(len(test_dataset))\n",
    "test_predictions = np.zeros(len(test_dataset))\n",
    "test_targets = np.zeros(len(test_dataset))\n",
    "with torch.no_grad():         \n",
    "    ptr = 0\n",
    "    for batch in test_loader:\n",
    "        users, movies, targets = batch\n",
    "        predictions = model(users.to('cuda'), movies.to('cuda'))\n",
    "        predictions = predictions.detach().cpu().numpy().flatten()\n",
    "        test_users[ptr:ptr + len(predictions)] = users.numpy().flatten()\n",
    "        test_predictions[ptr:ptr + len(predictions)] = predictions\n",
    "        test_targets[ptr:ptr + len(targets)] = targets.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_user_auc': 0.9796062694292754, 'auc': 0.6788107461266588}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(test_predictions, test_targets, test_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaPython",
   "language": "python",
   "name": "condapython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
