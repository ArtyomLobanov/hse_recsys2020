{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATING_THRESHOLD = 4\n",
    "PREFIX_LEN = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('big_data/rating.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movieId', 'title', 'genres'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv('big_data/movie.csv')\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_by_id = {movie_id: name for movie_id, name in zip(movies_df['movieId'], movies_df['title'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = max(df['userId']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_movies = max(df['movieId']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_by_user = defaultdict(list)\n",
    "requests_by_user = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userId, movieId, rating in zip(df['userId'], df['movieId'], df['rating']):\n",
    "    if rating > RATING_THRESHOLD:\n",
    "        items_by_user[userId].append(movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for userId, movies in items_by_user.items():\n",
    "    for i in range(PREFIX_LEN, len(movies)):\n",
    "        requests_by_user[userId].append((movies[i - PREFIX_LEN:i], movies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users with at least 9 ratings: 100243\n"
     ]
    }
   ],
   "source": [
    "print(f'Unique users with at least {PREFIX_LEN + 1} ratings: {len(requests_by_user)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requests_to_dataset(requests, n_movies, n_negative):\n",
    "    users, prev_movies, movies, targets = [], [], [], []\n",
    "    for user, session in requests.items():\n",
    "        for prev, movie in session:\n",
    "            users.append(user)\n",
    "            prev_movies.append(prev)\n",
    "            movies.append(movie)\n",
    "            targets.append(1)\n",
    "            \n",
    "            for i in range(n_negative):\n",
    "                users.append(user)\n",
    "                prev_movies.append(prev)\n",
    "                movies.append(random.randint(0, n_movies - 1))\n",
    "                targets.append(0)\n",
    "                \n",
    "    return TensorDataset(torch.LongTensor(users), torch.LongTensor(prev_movies), \n",
    "                         torch.LongTensor(movies), torch.FloatTensor(targets).view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_requests(requests):\n",
    "    train_requests, val_requests, test_requests = {}, {}, {}\n",
    "    for user, datas in requests.items():\n",
    "        user_cnt = len(datas)\n",
    "        train_size = (8 * user_cnt - 1) // 10 + 1\n",
    "        val_size = (user_cnt - train_size) // 2\n",
    "        \n",
    "        train_requests[user] = datas[:train_size]\n",
    "        val_requests[user] = datas[train_size:(train_size + val_size)]\n",
    "        test_requests[user] = datas[(train_size + val_size):]\n",
    "    return train_requests, val_requests, test_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_requests, val_requests, test_requests = split_requests(requests_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30850479\n"
     ]
    }
   ],
   "source": [
    "train_dataset = requests_to_dataset(train_requests, n_movies, 10)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3326873\n"
     ]
    }
   ],
   "source": [
    "val_dataset = requests_to_dataset(val_requests, n_movies, 10)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3326873\n"
     ]
    }
   ],
   "source": [
    "test_dataset = requests_to_dataset(test_requests, n_movies, 10)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, n_items, embeddings_dim=64, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.item_embedding = nn.Embedding(n_items, embeddings_dim)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(2 * embeddings_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(2 * embeddings_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1))\n",
    "\n",
    "    def forward(self, user, movies, item):\n",
    "        m = self.item_embedding(movies)\n",
    "        i = self.item_embedding(item)\n",
    "        \n",
    "        query = torch.cat([m, i.unsqueeze(-2).expand_as(m)], dim=-1)\n",
    "        weights = F.softmax(self.attention(query), dim=-2)\n",
    "        hidden = torch.cat([i, torch.sum(m * weights, dim=-2)], dim=-1)\n",
    "        \n",
    "        return self.predictor(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, opt, train, test, n_epochs, batch_size, device='cuda'):\n",
    "    train_loader = DataLoader(train, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test, batch_size, shuffle=False)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            users, prev_movies, movies, targets = batch\n",
    "            predictions = model(users.to(device), prev_movies.to(device), movies.to(device))\n",
    "            loss_value = loss(predictions, targets.to(device))\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_predictions = np.zeros(len(test))\n",
    "            test_targets = np.zeros(len(test))\n",
    "            \n",
    "            ptr = 0\n",
    "            for batch in test_loader:\n",
    "                users, prev_movies, movies, targets = batch\n",
    "                predictions = model(users.to(device), prev_movies.to(device), movies.to(device))\n",
    "                predictions = predictions.detach().cpu().numpy().flatten()\n",
    "                test_predictions[ptr:ptr + len(predictions)] = predictions\n",
    "                test_targets[ptr:ptr + len(targets)] = targets.numpy().flatten()\n",
    "            \n",
    "            print(f'After {i + 1} epochs AUC = {roc_auc_score(test_targets, test_predictions)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleAttention(n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1 epochs AUC = 0.7480036130889769\n",
      "After 2 epochs AUC = 0.7563702234837912\n",
      "After 3 epochs AUC = 0.774307173783972\n",
      "After 4 epochs AUC = 0.7896151573585418\n",
      "After 5 epochs AUC = 0.7835022350172225\n"
     ]
    }
   ],
   "source": [
    "train(model, loss, optimizer, train_dataset, val_dataset, 5, 25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.item_embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return x.dot(y) / (norm(x) * norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(embeddings, vector, n_samples=10):\n",
    "    results = []\n",
    "    for movie_id, movie_name in movie_by_id.items():\n",
    "        sim = cosine_similarity(embeddings[movie_id], vector)\n",
    "        results.append((sim, movie_id, movie_name))\n",
    "    results.sort(reverse=True)\n",
    "    return results[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similars_for(movie_id):\n",
    "    for sim, movie_id, movie_name in get_similar(embeddings, embeddings[movie_id]):\n",
    "        print(f'sim={sim:.2f}| id:{movie_id}\\t{movie_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim=1.00| id:76093\tHow to Train Your Dragon (2010)\n",
      "sim=0.43| id:4903\tIn the Bedroom (2001)\n",
      "sim=0.43| id:118930\tBill Burr: I'm Sorry You Feel That Way (2014)\n",
      "sim=0.43| id:7198\tPick-up Artist, The (1987)\n",
      "sim=0.42| id:1305\tParis, Texas (1984)\n",
      "sim=0.42| id:99446\tUltrasuede: In Search of Halston (2010)\n",
      "sim=0.42| id:96588\tPitch Perfect (2012)\n",
      "sim=0.42| id:27036\tMerlin (1998)\n",
      "sim=0.41| id:3980\tMen of Honor (2000)\n",
      "sim=0.41| id:82589\tMother and Child (2009)\n"
     ]
    }
   ],
   "source": [
    "show_similars_for(76093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim=1.00| id:480\tJurassic Park (1993)\n",
      "sim=0.47| id:410\tAddams Family Values (1993)\n",
      "sim=0.47| id:1014\tPollyanna (1960)\n",
      "sim=0.43| id:454\tFirm, The (1993)\n",
      "sim=0.42| id:4361\tTootsie (1982)\n",
      "sim=0.42| id:755\tKim (1950)\n",
      "sim=0.42| id:223\tClerks (1994)\n",
      "sim=0.42| id:2706\tAmerican Pie (1999)\n",
      "sim=0.41| id:2105\tTron (1982)\n",
      "sim=0.41| id:356\tForrest Gump (1994)\n"
     ]
    }
   ],
   "source": [
    "show_similars_for(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_movies(user_id):\n",
    "    requests = train_requests[user_id]\n",
    "    return requests[0][0] + [request[1] for request in requests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_user_recommendations(user_id):\n",
    "    train_movies = get_train_movies(user_id)\n",
    "    print('User movies:')\n",
    "    for movie_id in train_movies:\n",
    "        print(f'\\t{movie_by_id[movie_id]}')\n",
    "    recommendations = []\n",
    "    user = torch.LongTensor([user_id]).to('cuda')\n",
    "    movies = torch.LongTensor([train_movies]).to('cuda')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_movies):\n",
    "            score = model(user, movies, torch.LongTensor([i]).to('cuda')).item()\n",
    "            recommendations.append((score, i))\n",
    "    recommendations.sort(reverse=True)\n",
    "    print('\\nRecomendations:')\n",
    "    for score, i in recommendations[:10]:\n",
    "        print(f'\\t{movie_by_id[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User movies:\n",
      "\tAmerican President, The (1995)\n",
      "\tClueless (1995)\n",
      "\tWaiting to Exhale (1995)\n",
      "\tSense and Sensibility (1995)\n",
      "\tPersuasion (1995)\n",
      "\tApollo 13 (1995)\n",
      "\tBefore Sunrise (1995)\n",
      "\tBullets Over Broadway (1994)\n",
      "\tClerks (1994)\n",
      "\tHoop Dreams (1994)\n",
      "\tMiami Rhapsody (1995)\n",
      "\tRemains of the Day, The (1993)\n",
      "\n",
      "Recomendations:\n",
      "\tUsual Suspects, The (1995)\n",
      "\tFargo (1996)\n",
      "\tSchindler's List (1993)\n",
      "\tL.A. Confidential (1997)\n",
      "\tSilence of the Lambs, The (1991)\n",
      "\tApollo 13 (1995)\n",
      "\tLike Water for Chocolate (Como agua para chocolate) (1992)\n",
      "\tQuiz Show (1994)\n",
      "\tLittle Women (1994)\n",
      "\tFirm, The (1993)\n"
     ]
    }
   ],
   "source": [
    "show_user_recommendations(46380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User movies:\n",
      "\tMr. Holland's Opus (1995)\n",
      "\tFriday the 13th (1980)\n",
      "\tStar Wars: Episode VI - Return of the Jedi (1983)\n",
      "\tStar Trek: First Contact (1996)\n",
      "\tTerminator 2: Judgment Day (1991)\n",
      "\tStand by Me (1986)\n",
      "\tRules of Engagement (2000)\n",
      "\tFrom Russia with Love (1963)\n",
      "\tTime Machine, The (1960)\n",
      "\tFrom Dusk Till Dawn (1996)\n",
      "\tFemme Nikita, La (Nikita) (1990)\n",
      "\tJurassic Park (1993)\n",
      "\tFantastic Voyage (1966)\n",
      "\tLegends of the Fall (1994)\n",
      "\tAbbott and Costello Meet Frankenstein (1948)\n",
      "\tGrumpy Old Men (1993)\n",
      "\tAmityville Horror, The (1979)\n",
      "\tCreature from the Black Lagoon, The (1954)\n",
      "\tLost World: Jurassic Park, The (1997)\n",
      "\t2001: A Space Odyssey (1968)\n",
      "\tStar Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\tBack to the Future (1985)\n",
      "\tAlien (1979)\n",
      "\n",
      "Recomendations:\n",
      "\tShawshank Redemption, The (1994)\n",
      "\tPulp Fiction (1994)\n",
      "\tGodfather, The (1972)\n",
      "\tUsual Suspects, The (1995)\n",
      "\tSchindler's List (1993)\n",
      "\tBraveheart (1995)\n",
      "\tSilence of the Lambs, The (1991)\n",
      "\tRaiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\tSeven (a.k.a. Se7en) (1995)\n",
      "\tForrest Gump (1994)\n"
     ]
    }
   ],
   "source": [
    "show_user_recommendations(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets, users):\n",
    "    user_pred = {}\n",
    "    user_target = {}\n",
    "    for p, t, user in zip(pred, targets, users):\n",
    "        if user not in user_pred:\n",
    "            user_pred[user] = []\n",
    "            user_target[user] = []\n",
    "        user_pred[user].append(p)\n",
    "        user_target[user].append(t)\n",
    "    auc_per_user = []\n",
    "    for user in user_pred:\n",
    "        try:\n",
    "            auc_per_user.append(roc_auc_score(user_target[user], user_pred[user]))\n",
    "        except ValueError:\n",
    "            auc_per_user.append(0.5)\n",
    "    metric_values = {\n",
    "        'per_user_auc': np.mean(auc_per_user), \n",
    "        'auc': roc_auc_score(targets, pred)\n",
    "    }\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, 50000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_users = np.zeros(len(test_dataset))\n",
    "test_predictions = np.zeros(len(test_dataset))\n",
    "test_targets = np.zeros(len(test_dataset))\n",
    "with torch.no_grad():         \n",
    "    ptr = 0\n",
    "    for batch in test_loader:\n",
    "        users, prev_movies, movies, targets = batch\n",
    "        predictions = model(users.to('cuda'), prev_movies.to('cuda'), movies.to('cuda'))\n",
    "        predictions = predictions.detach().cpu().numpy().flatten()\n",
    "        test_users[ptr:ptr + len(predictions)] = users.numpy().flatten()\n",
    "        test_predictions[ptr:ptr + len(predictions)] = predictions\n",
    "        test_targets[ptr:ptr + len(targets)] = targets.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'per_user_auc': 0.9806393391258358, 'auc': 0.7688662538466688}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(test_predictions, test_targets, test_users)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaPython",
   "language": "python",
   "name": "condapython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
